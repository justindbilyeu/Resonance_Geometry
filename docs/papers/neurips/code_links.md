# Code â†’ Results Mapping

*Full provenance for reproducibility*

---

## Figure 1: Phase Diagram (Grounded/Creative/Hallucinatory Regimes)

**Result**: Three-regime phase diagram in (Î·, Î») space with linear boundary

**Generated by**:
- **Script**: `rg/sims/meta_flow_min_pair_v2.py` 
  - *Note*: Will be moved to `src/resonance_geometry/hallucination/phase_dynamics.py`
- **Alternative**: `rg/validation/phase_boundary_fit.py`

**Parameters**:
```python
eta_range = [0.2, 5.0]  # 101 steps
lambda_range = [0.1, 5.0]  # 11 steps
gamma = 0.5
alpha = 0.6  # saturation (quintic)
beta = 0.02  # saturation (cubic)
kappa = 0.12  # coupling skew
mi_window = 30
mi_ema = 0.1
dt = 0.01
T = 6.0
```

**Output**:

- Data: `results/phase_diagram_v2.csv` (or similar)
- Figure: `figures/phase_diagram_v2.png`

**Reproduction command** (after reorganization):

```bash
python experiments/hallucination/run_phase_diagram.py \
  --gamma 0.5 --alpha 0.6 --beta 0.02 --skew 0.12 \
  --eta_min 0.2 --eta_max 5.0 --eta_steps 101 \
  --lam_min 0.1 --lam_max 5.0 --lam_steps 11 \
  --mi_window 30 --mi_ema 0.1 \
  --T 6.0 --dt 0.01 --seed 42 \
  --out_dir results/phase_diagram/
```

**Key result**: Linear boundary Î·Â·Äª â‰ˆ Î» + Î³ with RÂ² â‰ˆ 0.95

**Commit**: [To be filled after code stabilizes]

-----

## Figure 2: Hysteresis Loops

**Result**: Forward/backward sweeps showing first-order transition, max loop gap â‰ˆ 11.52

**Generated by**:

- **Script**: `rg/validation/hysteresis_sweep.py`
  - *Note*: Will be moved to `experiments/hallucination/`

**Parameters**:

```python
lambda_fixed = 1.0
gamma = 0.5
alpha = 0.6
beta = 0.02
skew = 0.12
eta_sweep = [0.2, 5.0]  # Forward then backward
```

**Output**:

- Data: `results/hysteresis_v2.csv`
- Figure: `figures/hysteresis_v2.png`

**Reproduction command**:

```bash
python experiments/hallucination/run_hysteresis.py \
  --lam 1.0 --gamma 0.5 --alpha 0.6 --beta 0.02 --skew 0.12 \
  --eta_min 0.2 --eta_max 5.0 --eta_steps 50 \
  --forward_backward --seed 42 \
  --out_dir results/hysteresis/
```

**Key result**: Max vertical gap â‰ˆ 11.52 indicates memory/metastability

**Commit**: [TBD]

-----

## Figure 3+: Empirical Results (TruthfulQA)

**Status**: ðŸ”„ In progress (Q1 2025)

**Planned figures**:

1. ROC curve (Î»_max as hallucination predictor)
1. Layer-wise analysis (first crossing location)
1. Intervention effect (temperature/RAG)
1. Calibration curve

**Will be generated by**:

- **Script**: `experiments/hallucination/run_truthfulqa_extraction.py` (to be created)
- **Analysis**: `experiments/hallucination/analyze_results.py` (to be created)

**Parameters** (pre-registered):

```python
model = "gpt2-medium"  # 355M params
benchmark = "TruthfulQA"
n_samples = 100  # Stratified: 40 hallucinated, 20 borderline, 40 clean
k_neighbors = 15  # For k-NN graph
layers = [0, 1, ..., 23]  # All 24 layers
curvature_type = "laplacian_symmetric"
threshold_method = "median"  # Of clean samples
```

**Expected output**:

- Data: `results/truthfulqa/*.csv`
- Figures: `figures/roc_curve.png`, `figures/layer_analysis.png`, etc.

**Reproduction command** (planned):

```bash
python experiments/hallucination/run_truthfulqa_extraction.py \
  --model gpt2-medium \
  --benchmark truthfulqa \
  --n_samples 100 \
  --k_neighbors 15 \
  --curvature_type laplacian_symmetric \
  --seed 42 \
  --out_dir results/truthfulqa/
```

**Commit**: [TBD after implementation]

-----

## Supplementary Figures (Appendix)

### S1: Ablation Studies

- No damping (Î³=0)
- No saturation (Î±=Î²=0)
- No coupling (Îº=0)

**Script**: Same as Figure 1, with parameter variations

### S2: Different MI Estimators

- Correlation-based vs SVD-based
- Different window sizes

**Script**: `rg/validation/mi_sensitivity.py` (if exists)

### S3: Sensitivity Analysis

- Robustness to hyperparameters
- Different random seeds

**Script**: Variations of main scripts with parameter sweeps

-----

## Dependencies

### Python Packages

```
numpy>=1.24.0
scipy>=1.10.0
matplotlib>=3.7.0
pandas>=2.0.0
torch>=2.0.0  # For LLM work
transformers>=4.30.0  # For model loading
scikit-learn>=1.3.0  # For k-NN graphs
```

See `requirements.txt` in root

### External Data

- **TruthfulQA dataset**: Download from [link]
- **Pre-trained models**: Loaded via HuggingFace transformers

-----

## Verification Checklist

Before claiming reproducibility:

- [ ] All scripts run without errors
- [ ] Random seeds produce identical outputs
- [ ] Figures match paper exactly
- [ ] Data files include metadata (params, timestamp, commit hash)
- [ ] README in results/ explains file formats
- [ ] Tests pass for all critical functions

-----

## Known Issues / Caveats

1. **Floating point**: Results may vary slightly across platforms due to numerical precision
1. **Random seeds**: Python/NumPy RNG state must be set identically
1. **Library versions**: Exact version matching required for perfect reproduction
1. **Compute**: Some experiments may require GPU (note in README if so)

-----

## Future: Full Reproducibility Pack

Plan for v2.0:

- [ ] Docker container with frozen environment
- [ ] One-command reproduction script
- [ ] Checksums for all outputs
- [ ] Continuous integration tests
- [ ] Archived on Zenodo with DOI

-----

*Last updated: 2025-01-[DATE]*
*Maintainer: Justin Bilyeu*

